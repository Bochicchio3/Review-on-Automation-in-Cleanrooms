
@article{Overview_of_Active_Vision_Techniques,
	title = {Overview of Active Vision Techniques},
	pages = {24},
	author = {Curless, Brian},
	langid = {english},
	file = {Curless - Overview of Active Vision Techniques.pdf:/home/alfredo/Zotero/storage/AKM2FNJF/Curless - Overview of Active Vision Techniques.pdf:application/pdf}
}

@article{adaptive_measurement,
	title = {Online adaptive measurement and adjustment for flexible part during high precision drilling process},
	volume = {89},
	issn = {1433-3015},
	url = {https://doi.org/10.1007/s00170-016-9274-0},
	doi = {10.1007/s00170-016-9274-0},
	abstract = {Shape of flexible part is easy to be out of tolerances due to deformations in the clamping and machining process. These deformations are generated randomly and hard to be predicted. Surface normal drilling and countersinking of flexible part is commonly necessary in aircraft assembly process. An online high precision surface normal measurement and cutter orientation compensation method is developed for adaptively drilling of flexible part in this paper. During the process of normal measurement and adjustment, the distance from tool nose to drilling point is accurately measured and adjusted synchronously, which is critical for countersinking. To accurately measure the current normal of the deformed workpiece, two 2D laser displacement sensors are applied to measure the surface profiles of the workpiece and sample two sets of geometrical points each time. Two crossed spatial curves are respectively fitted by the two sets of geometrical points, and the surface normal at the intersection point of the crossed curves is computed. After the deviation between the measured normal and tool orientation is calculated, an online compensation method is used to eliminate the deviation and meet the perpendicularity requirement of the cutter axis to the workpiece surface, and the distance from tool nose to drilling point is measured and adjusted to the setting value synchronously. The compensation method is based on the kinematic transformation of a five-axis machine tool and is implemented by {NC} compensation. Simulations and experiments are conducted to validate the feasibility and effectiveness of the online adaptive measurement and adjustment method.},
	pages = {3579--3599},
	number = {9},
	journaltitle = {The International Journal of Advanced Manufacturing Technology},
	shortjournal = {Int J Adv Manuf Technol},
	author = {Zhang, Yilian and Bi, Qingzhen and Yu, Long and Wang, Yuhan},
	urldate = {2019-08-16},
	date = {2017-04-01},
	langid = {english},
	keywords = {Countersinking, Five-axis kinematic transformation, Normal drilling, Online compensation, Surface normal measurement}
}

@inproceedings{sub_pixel_laser_spot,
	title = {Analysis of sub-pixel laser spot detection in laser triangulation systems},
	volume = {11056},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11056/110563O/Analysis-of-sub-pixel-laser-spot-detection-in-laser-triangulation/10.1117/12.2525669.short},
	doi = {10.1117/12.2525669},
	abstract = {Laser spot detection is an important step of laser triangulation and limits its accuracy. Common methods to determine the center position include circle fitting, the Hough transformation, the gray centroid method or Gaussian fitting. As these algorithms were often tested in different set-ups and under various conditions, they generally lead to diverse results. The aim of this contribution is to investigate the algorithms in a more objective and realistic approach. After a short introduction to laser triangulation, basic information about laser spot center detection is given. Fundamental limitations of the laser spot detection are then considered and analyzed. The investigations are followed by evaluations of measurements in a real laser triangulation setup. Through this approach we could show that the influence of the spatial quantization and the quantization due to the limited bit depth of the detector can be in a similar range as the deviation due to speckle noise in the image. By using adapted image processing steps, the performance of the laser spot center determination could be improved significantly.},
	eventtitle = {Optical Measurement Systems for Industrial Inspection {XI}},
	pages = {110563O},
	booktitle = {Optical Measurement Systems for Industrial Inspection {XI}},
	publisher = {International Society for Optics and Photonics},
	author = {Kienle, Patrick and Nallar, Elif and Köhler, Michael H. and Jakobi, Martin and Koch, Alexander W.},
	urldate = {2019-08-16},
	date = {2019-06-21},
	file = {Full Text PDF:/home/alfredo/Zotero/storage/4D24TPHB/Kienle et al. - 2019 - Analysis of sub-pixel laser spot detection in lase.pdf:application/pdf;Snapshot:/home/alfredo/Zotero/storage/AN9TRRNX/12.2525669.html:text/html}
}

@article{structured-light-based_2018,
	title = {Structured-Light-Based System for Shape Measurement of the Human Body in Motion},
	volume = {18},
	issn = {1424-8220},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6165049/},
	doi = {10.3390/s18092827},
	abstract = {The existing methods for measuring the shape of the human body in motion are limited in their practical application owing to immaturity, complexity, and/or high price. Therefore, we propose a method based on structured light supported by multispectral separation to achieve multidirectional and parallel acquisition. Single-frame fringe projection is employed in this method for detailed geometry reconstruction. An extended phase unwrapping method adapted for measurement of the human body is also proposed. This method utilizes local fringe parameter information to identify the optimal unwrapping path for reconstruction. Subsequently, we present a prototype 4DBODY system with a working volume of 2.0 × 1.5 × 1.5 m3, a measurement uncertainty less than 0.5 mm and an average spatial resolution of 1.0 mm for three-dimensional (3D) points. The system consists of eight directional 3D scanners functioning synchronously with an acquisition frequency of 120 Hz. The efficacy of the proposed system is demonstrated by presenting the measurement results obtained for known geometrical objects moving at various speeds as well actual human movements.},
	number = {9},
	journaltitle = {Sensors (Basel, Switzerland)},
	shortjournal = {Sensors (Basel)},
	author = {Liberadzki, Paweł and Adamczyk, Marcin and Witkowski, Marcin and Sitnik, Robert},
	urldate = {2019-08-16},
	date = {2018-08-27},
	pmid = {30150558},
	pmcid = {PMC6165049},
	file = {PubMed Central Full Text PDF:/home/alfredo/Zotero/storage/83DXSCX5/Liberadzki et al. - 2018 - Structured-Light-Based System for Shape Measuremen.pdf:application/pdf}
}

@article{laser_displacement,
	title = {A flexible calibration method for laser displacement sensors based on a stereo-target},
	volume = {25},
	issn = {0957-0233},
	url = {https://doi.org/10.1088%2F0957-0233%2F25%2F10%2F105103},
	doi = {10.1088/0957-0233/25/10/105103},
	abstract = {Laser displacement sensors ({LDSs}) are widely used in online measurement owing to their characteristics of non-contact, high measurement speed, etc. However, existing calibration methods for {LDSs} based on the traditional triangulation measurement model are time-consuming and tedious to operate. In this paper, a calibration method for {LDSs} based on a vision measurement model of the {LDS} is presented. According to the constraint relationships of the model parameters, the calibration is implemented by freely moving a stereo-target at least twice in the field of view of the {LDS}. Both simulation analyses and real experiments were conducted. Experimental results demonstrate that the calibration method achieves an accuracy of 0.044 mm within the measurement range of about 150 mm. Compared to traditional calibration methods, the proposed method has no special limitation on the relative position of the {LDS} and the target. The linearity approximation of the measurement model in the calibration is not needed, and thus the measurement range is not limited in the linearity range. It is easy and quick to implement the calibration for the {LDS}. The method can be applied in wider fields.},
	pages = {105103},
	number = {10},
	journaltitle = {Measurement Science and Technology},
	shortjournal = {Meas. Sci. Technol.},
	author = {Zhang, Jie and Sun, Junhua and Liu, Zhen and Zhang, Guangjun},
	urldate = {2019-08-16},
	date = {2014-09},
	langid = {english},
	file = {IOP Full Text PDF:/home/alfredo/Zotero/storage/T6PT2JN7/Zhang et al. - 2014 - A flexible calibration method for laser displaceme.pdf:application/pdf}
}

@inreference{3d_structured-light_scanner_2019,
	title = {Structured-light 3D scanner},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Structured-light_3D_scanner&oldid=906459934},
	abstract = {A structured-light 3D scanner is a 3D scanning device for measuring the three-dimensional shape of an object using projected light patterns and a camera system.},
	booktitle = {Wikipedia},
	urldate = {2019-08-16},
	date = {2019-07-16},
	langid = {english},
	note = {Page Version {ID}: 906459934},
	file = {Snapshot:/home/alfredo/Zotero/storage/RP8GBBIS/index.html:text/html}
}

@article{Zed_data_error,
	title = {Depth Data Error Modeling of the {ZED} 3D Vision Sensor from Stereolabs},
	volume = {17},
	doi = {10.5565/rev/elcvia.1084},
	abstract = {The {ZED} camera is binocular vision system that can be used to provide a 3D perception of the world. It can be applied in autonomous robot navigation, virtual reality, tracking, motion analysis and so on. This paper proposes a mathematical error model for depth data estimated by the {ZED} camera with its several resolutions of operation. For doing that, the {ZED} is attached to a Nvidia Jetson {TK}1 board providing an embedded system that is used for processing raw data acquired by {ZED} from a 3D checkerboard. Corners are extracted from the checkerboard using {RGB} data, and a 3D reconstruction is done for these points using disparity data calculated from the {ZED} camera, coming up with a partially ordered, and regularly distributed (in 3D space) point cloud of corners with given coordinates (x e , y e , z e), which are computed by the device software. These corners also have their ideal world (3D) positions (x i , y i , z i) known with respect to the coordinate frame origin that is empirically set in the pattern. Both given (computed) coordinates from the camera's data and known (ideal) coordinates of a corner can, thus, be compared for estimating the error between the given and ideal point locations of the detected corner cloud. Subsequently, using a curve fitting technique, we obtain the equations that model the {RMS} (Root Mean Square) error. This procedure is repeated for several resolutions of the {ZED} sensor, and at several distances. Results showed its best effectiveness with a maximum distance of approximately sixteen meters, in real time, which allows its use in robotic or other online applications.},
	journaltitle = {Electronic Letters on Computer Vision and Image Analysis},
	shortjournal = {Electronic Letters on Computer Vision and Image Analysis},
	author = {Ortiz, Luis and Cabrera, Elizabeth and Gonçalves, Luiz},
	date = {2018-04-03},
	file = {Full Text PDF:/home/alfredo/Zotero/storage/IFYLJVXT/Ortiz et al. - 2018 - Depth Data Error Modeling of the ZED 3D Vision Sen.pdf:application/pdf}
}

@inproceedings{Laser_triangulation,
	title = {Measurement of Free-Form Curved Surfaces Using Laser Triangulation},
	doi = {10.3390/s18103527},
	abstract = {Laser triangulation ({LT}) is widely used in many fields due to its good stability, high resolution and fast speed. However, the accuracy in these applications suffers from severe constraints on the data acquisition accuracy of {LT}. To solve this problem, the optical triangulation principle, the object equation of the optical path relationship and the deviation of the laser spot centroid are applied to deduce a mathematical model. Therefore, the image sensor inclination errors can be quantitatively calculated, and the collected data are compensated in real time. Further, a threshold sub-pixel gray-gravity ({GG}) extraction algorithm is proposed; the gradient function and Gaussian fit algorithm are used to set thresholds to remove the impact of the spot edge noise area on the center location; and polynomial interpolation is employed to enhance the data density of the traditional {GG} method, thus improving the data acquisition accuracy of {LT}. Finally, the above methods are applied to on-machine measurement of the American Petroleum Institute ({API}) thread and the screw rotor, respectively. The experimental results prove that the proposed method can significantly improve the measurement accuracy of free-form curved surfaces using {LT} and that the improved laser spot center extraction algorithm is more suitable for free-form curved surfaces with smaller curvature and more uniform curvature changes.},
	booktitle = {Sensors},
	author = {Dong, Zhixu and Sun, Xingwei and Liu, Weijun and Yang, Heran},
	date = {2018},
	keywords = {algorithm, Algorithm, Areal density (computer storage), Data acquisition, Experiment, Gadu-Gadu, Gradient, Image resolution, Image sensor, Interference (communication), Interpolation Imputation Technique, Mathematical model, Mathematics, Mental Suffering, Normal Statistical Distribution, Pixel, Polynomial interpolation, R.O.T.O.R., Small, triangulation},
	file = {Full Text PDF:/home/alfredo/Zotero/storage/I26R6QUB/Dong et al. - 2018 - Measurement of Free-Form Curved Surfaces Using Las.pdf:application/pdf}
}

@article{Binocular_3d_scanner,
	title = {Build 3D Scanner System based on Binocular Stereo Vision},
	volume = {7},
	doi = {10.4304/jcp.7.2.jcp0702399404},
	abstract = {This paper presents such a low-cost and simple 3D Scanner System. The necessary hardware is a hand-held line laser and two same standard cameras. The System can obtain 3D information of object and importantly this method is simple and effective. So it is very easy-to-use, and the results can be satisfied for normal users.},
	pages = {0702399404},
	journaltitle = {{JCP}},
	author = {Lv, Zhihua and Zhang, Zhiyi},
	date = {2012},
	keywords = {3D scanner, Binocular vision, Mobile device, Pinhole camera model, Sobel operator, Stereopsis},
	file = {Full Text PDF:/home/alfredo/Zotero/storage/INEKSAYP/Lv e Zhang - 2012 - Build 3D Scanner System based on Binocular Stereo .pdf:application/pdf}
}

@online{slr_camera_Python,
	title = {Control an {SLR} Camera from Python (Nikon, Canon, Sony, etc…) – Scott Lobdell},
	url = {http://scottlobdell.me/2014/02/control-an-slr-camera-from-python-nikon-canon-sony-etc/},
	urldate = {2019-08-16},
	file = {Control an SLR Camera from Python (Nikon, Canon, Sony, etc…) – Scott Lobdell:/home/alfredo/Zotero/storage/4BKZAYW4/control-an-slr-camera-from-python-nikon-canon-sony-etc.html:text/html}
}

@online{noauthor_zed-python-api/tutorials_nodate,
	title = {zed-python-api/tutorials at master · stereolabs/zed-python-api},
	url = {https://github.com/stereolabs/zed-python-api},
	urldate = {2019-08-16},
	file = {zed-python-api/tutorials at master · stereolabs/zed-python-api:/home/alfredo/Zotero/storage/9BTQCDLS/zed-python-api.html:text/html}
}

@software{3d_scanner_structured_light,
	title = {Engineering degree thesis: Structured Light based 3D Scanner - nikolaseu/thesis},
	url = {https://github.com/nikolaseu/thesis},
	shorttitle = {Engineering degree thesis},
	author = {Ulrich, Nicolas},
	urldate = {2019-08-21},
	date = {2019-04-25},
	note = {original-date: 2017-03-14T15:05:15Z}
}

@software{ulrich_structured_2019,
	title = {Structured Light based 3D scanner. Contribute to nikolaseu/neuvision development by creating an account on {GitHub}},
	rights = {{GPL}-3.0},
	url = {https://github.com/nikolaseu/neuvision},
	author = {Ulrich, Nicolas},
	urldate = {2019-08-21},
	date = {2019-08-21},
	note = {original-date: 2016-12-23T18:42:10Z}
}

@software{witt_opencv-based_2019,
	title = {An {OpenCV}-based structured light processing toolkit.: jhdewitt/sltk},
	rights = {{MIT}},
	url = {https://github.com/jhdewitt/sltk},
	shorttitle = {An {OpenCV}-based structured light processing toolkit.},
	author = {Witt, John De},
	urldate = {2019-08-21},
	date = {2019-08-21},
	note = {original-date: 2015-03-31T06:44:01Z}
}

@software{out-sider_cheap_2018,
	title = {a cheap optical 3D scanner programmed with python (and {OpenCV}, numpy, Arduino): out-sider/3D-scanner},
	rights = {{LGPL}-3.0},
	url = {https://github.com/out-sider/3D-scanner},
	shorttitle = {a cheap optical 3D scanner programmed with python (and {OpenCV}, numpy, Arduino)},
	author = {out-sider},
	urldate = {2019-08-21},
	date = {2018-06-11},
	note = {original-date: 2017-09-25T02:40:17Z}
}

@software{ulrich_engineering_2019-1,
	title = {Engineering degree thesis: Structured Light based 3D Scanner - nikolaseu/thesis},
	url = {https://github.com/nikolaseu/thesis},
	shorttitle = {Engineering degree thesis},
	author = {Ulrich, Nicolas},
	urldate = {2019-08-21},
	date = {2019-04-25},
	note = {original-date: 2017-03-14T15:05:15Z}
}

@online{hoiem_maximize_2018,
	title = {Maximize measurement accuracy with images overlaid on point clouds},
	url = {https://medium.com/reconstruct-inc/maximize-measurement-accuracy-with-images-overlaid-on-point-clouds-dca828f4a539},
	abstract = {The accuracy of a 3D measurement depends both on the accuracy of the reconstructed model and the ability of the user to select the right…},
	titleaddon = {Medium},
	author = {Hoiem, Derek},
	urldate = {2019-09-10},
	date = {2018-01-17},
	langid = {english},
	file = {Snapshot:/home/alfredo/Zotero/storage/98KBSNVK/maximize-measurement-accuracy-with-images-overlaid-on-point-clouds-dca828f4a539.html:text/html}
}

@article{he_study_2003,
	title = {Study on method for processing image of strip in structured-light 3D vision measuring technique},
	volume = {29},
	abstract = {In a structured-light vision system, the accuracy of center position of the stripe is of great importance for that of the whole measuring system. Processing the image of stripe is an important step, especially for images with serious noises. Methods for processing images of stripe disturbed by various noise sources were discussed, as well as the method for detecting accurately the center of stripes, A special filtering mask was submitted for surrounding disturbance and was verified effective. For the measuring range as large as 200 mm×200 mm the accuracy of the whole measuring system when using the methods mentioned is 0.083 mm.},
	pages = {593--597},
	author = {He, J. and Zhang, G.},
	date = {2003-07-01}
}

@inproceedings{munoz_fast_2016,
	title = {Fast 6D pose estimation for texture-less objects from a single {RGB} image},
	doi = {10.1109/ICRA.2016.7487781},
	abstract = {A fundamental step to solve bin-picking and grasping problems is the accurate estimation of an object 3D pose. Such visual task usually rely on profusely textured objects: standard procedures such as detection of interest points or computation of appearance-based descriptors are favoured by using a highly informative surface. However, texture-less objects or their parts (i.e., those whose surface texture is poorly conditioned) are common in any environment but still challenging to deal with. This is due the fact that the distribution of surface brightness makes difficult to compute interest points or appearance-based descriptors. In this paper, we propose a method to estimate the 3D pose for texture-less objects given a coarse initialization: the pose is estimated using using edge correspondences, where the similarity measure is encoded using a pre-computed linear regression matrix. Furthermore, we also propose a method to increase the robustness of the estimated pose against background and object clutter. We validate both methods by using synthetic and real image sequences with objects with known ground truth.},
	eventtitle = {2016 {IEEE} International Conference on Robotics and Automation ({ICRA})},
	pages = {5623--5630},
	booktitle = {2016 {IEEE} International Conference on Robotics and Automation ({ICRA})},
	author = {Muñoz, E. and Konishi, Y. and Murino, V. and Bue, A. Del},
	date = {2016-05},
	keywords = {Image edge detection, Three-dimensional displays, 3D pose estimation, background clutter, coarse initialization, Computational modeling, edge correspondences, edge detection, fast 6D pose estimation, image sequences, linear regression matrix, matrix algebra, object clutter, pose estimation, regression analysis, Robustness, similarity measure, single {RGB} image, Solid modeling, texture-less objects, Training},
	file = {IEEE Xplore Abstract Record:/home/alfredo/Zotero/storage/UT4M323K/7487781.html:text/html}
}

@inproceedings{bing_energy-efficient_2019,
	location = {Macao, China},
	title = {Energy-Efficient Slithering Gait Exploration for a Snake-Like Robot Based on Reinforcement Learning},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/785},
	doi = {10.24963/ijcai.2019/785},
	abstract = {Similar to their counterparts in nature, the ﬂexible bodies of snake-like robots enhance their movement capability and adaptability in diverse environments. However, this ﬂexibility corresponds to a complex control task involving highly redundant degrees of freedom, where traditional modelbased methods usually fail to propel the robots energy-efﬁciently. In this work, we present a novel approach for designing an energy-efﬁcient slithering gait for a snake-like robot using a model-free reinforcement learning ({RL}) algorithm. Speciﬁcally, we present an {RL}-based controller for generating locomotion gaits at a wide range of velocities, which is trained using the proximal policy optimization ({PPO}) algorithm. Meanwhile, a traditional parameterized gait controller is presented and the parameter sets are optimized using the grid search and Bayesian optimization algorithms for the purposes of reasonable comparisons. Based on the analysis of the simulation results, we demonstrate that this {RLbased} controller exhibits very natural and adaptive movements, which are also substantially more energy-efﬁcient than the gaits generated by the parameterized controller. Videos are shown at https://videoviewsite.wixsite.com/rlsnake.},
	eventtitle = {Twenty-Eighth International Joint Conference on Artificial Intelligence \{{IJCAI}-19\}},
	pages = {5663--5669},
	booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Bing, Zhenshan and Lemke, Christian and Jiang, Zhuangyi and Huang, Kai and Knoll, Alois},
	urldate = {2019-11-05},
	date = {2019-08},
	langid = {english},
	file = {Bing et al. - 2019 - Energy-Efficient Slithering Gait Exploration for a.pdf:/home/alfredo/Zotero/storage/K7ZDPBX5/Bing et al. - 2019 - Energy-Efficient Slithering Gait Exploration for a.pdf:application/pdf}
}


@inproceedings{AutomationPhotovoltaic,
  title={Lightweight Robotic Material Handling in Photovoltaic Module Manufacturing-Silicon Wafer and Thin Film Technologies},
  author={Nima Asadi and Maddalena Jackson},
  year={2012}
}


@misc{magnetometer,
  title={Method and device for pose tracking using vector magnetometers},
  author={Gustafsson, Fredrik BR and Wahlstr{\"o}m, Niklas T},
  year={2019},
  month=mar # "~12",
  publisher={Google Patents},
  note={US Patent 10,228,428}
}


@article{fiberopticsshapesensing,
author = {Amanzadeh, Moe and Aminossadati, Saiied and Kizil, M. and Rakić, Aleksandar},
year = {2018},
month = {06},
pages = {},
title = {Recent Developments in Fibre Optic Shape Sensing},
volume = {128},
journal = {Measurement},
doi = {10.1016/j.measurement.2018.06.034}
}